{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oGdUA_yej9-M"
      },
      "outputs": [],
      "source": [
        "!pip install transformers datasets accelerate -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile text_generation.py\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "generator = pipeline(\"text-generation\", model=\"aubmindlab/aragpt2-base\")\n",
        "\n",
        "prompts = [\n",
        "    \"في إحدى ليالي الشتاء الباردة\",\n",
        "    \"تحب دانية الذهاب إلى عملها بسبب\",\n",
        "    \"كان الأطفال يلعبون في الملعب ثم\"\n",
        "]\n",
        "\n",
        "for i, prompt in enumerate(prompts, start=1):\n",
        "    print(\"=\" * 40)\n",
        "    print(f\"Prompt {i}: {prompt}\")\n",
        "\n",
        "    output = generator(\n",
        "        prompt,\n",
        "        max_length=40,\n",
        "        do_sample=False,\n",
        "        top_k=50,\n",
        "        top_p=0.95\n",
        "    )[0][\"generated_text\"]\n",
        "\n",
        "    print(\"Generated Text:\")\n",
        "    print(output)\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SwpRHzhcl0c0",
        "outputId": "94e0b2eb-5570-4d6a-a927-674781f424b7"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting text_generation.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python text_generation.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRCXUeFFqY6k",
        "outputId": "e908d44e-0d85-4756-a871-14a28b652220"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-09 20:11:08.605599: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765311068.648602   11647 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765311068.660688   11647 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765311068.691691   11647 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765311068.691777   11647 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765311068.691782   11647 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765311068.691786   11647 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-09 20:11:08.701708: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Device set to use cpu\n",
            "========================================\n",
            "Prompt 1: في إحدى ليالي الشتاء الباردة\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=40) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Generated Text:\n",
            "في إحدى ليالي الشتاء الباردة ، وبينما هو جالس على أريكة في أحد المقاهي القريبة من منزله ، سمع صوتا غريبا ينبعث من غرفة نومه ، فهرع إلى الغرفة المجاورة ليجدها خالية تماما.فجأة فتح باب الغرفة ليرى ما يحدث ، فإذا به يسمع صوت سيارة مسرعة يقودها شخص مجهول ، وإذا بأحد المارة يقول له : \" هيا بنا لنرى ماذا يحدث ؟ \"فأجابه السائق : \" لا تقلق يا سيدي ، لقد سمعنا أصواتا غريبة قادمة من الخارج ، ولكن لم نسمع أي شيء حتى الآن \".فقال الرجل : \" إن هذا الصوت غريب نوعا ما ، فهو يشبه صوت السيارة التي تسير بسرعة جنونية ، ولا يمكن أن تسمعه إلا إذا كنت قادما من مكان بعيد \".وبعد عدة دقائق وجد الرجل نفسه وسط مجموعة كبيرة من الناس الذين تجمعوا حوله ليروا ما حدث ، وعندما شاهدهم قال لهم : \" هل رأيتم شيئا غريبا كهذا ؟ \"وإذا كان الأمر كذلك ، فما عليك إلا أن تذهب إلى المكان الذي يوجد فيه الشخص المجهول وتخبره بما حدث.\n",
            "\n",
            "========================================\n",
            "Prompt 2: تحب دانية الذهاب إلى عملها بسبب\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=40) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Generated Text:\n",
            "تحب دانية الذهاب إلى عملها بسبب ظروف العمل ، حيث أنها لا تستطيع أن تعمل في أي مكان إلا إذا كان لديها عمل آخر.وتقول دانية : “ عندما كنت أعمل في إحدى الشركات ، لم يكن لدي وقت كافي للذهاب إلى العمل ”.ومنذ ذلك الحين ، أصبحت دانية من أكثر النساء العاملات في مجال الأعمال التجارية على مستوى العالم ، وذلك بفضل خبرتها التي تمتد لأكثر من 30 عاما في هذا المجال.وأصبحت دانية واحدة من بين العديد من النساء اللواتي يعملن في مجالات مختلفة مثل تجارة التجزئة ، وتجارة الجملة والتجزئة ، والتجارة الإلكترونية ، والتسويق عبر البريد الإلكتروني ، والاتصالات السلكية واللاسلكية ، وغيرها الكثير.وقالت دانية لصحيفة “ ديلي ميل ” البريطانية : “ أنا سعيدة جدا لأنني تمكنت من الحصول على وظيفتي الجديدة بعد فترة طويلة من العمل الشاق ”.وكانت دانية قد حصلت على شهادة الماجستير في إدارة الأعمال من جامعة ستانفورد في الولايات المتحدة الأمريكية عام 2012 ، وهي حاصلة على درجة البكالوريوس في علوم الحاسب الآلي من جامعة كاليفورنيا في بيركلي.وبعد حصولها على هذه الشهادة ، عملت دانية مع مجموعة من أكبر شركات البرمجيات في المملكة المتحدة ، بما في ذلك مايكروسوفت ، وجوجل ، ومايكروسوفت ، وأمازون ، وفيسبوك ، وإنستاجرام ، وآي أو إس ، وبلاكبيري ، وكوالكوم ، وهواوي ، وتوشيبا ، وشيفرولية\n",
            "\n",
            "========================================\n",
            "Prompt 3: كان الأطفال يلعبون في الملعب ثم\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=40) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Generated Text:\n",
            "كان الأطفال يلعبون في الملعب ثم يعودون إلى منازلهم بعد انتهاء المباراة.ومنذ ذلك الحين ، أصبح اللعب جزءا لا يتجزأ من الحياة اليومية للأطفال الذين تتراوح أعمارهم بين 6 و 14 عاما.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile summarization_qa.py\n",
        "\n",
        "from transformers import pipeline\n",
        "\n",
        "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "qa = pipeline(\"question-answering\", model=\"distilbert-base-cased-distilled-squad\")\n",
        "\n",
        "with open(\"article.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    article = f.read()\n",
        "\n",
        "summary = summarizer(\n",
        "    article,\n",
        "    max_length=130,\n",
        "    min_length=30,\n",
        "    do_sample=False\n",
        ")[0][\"summary_text\"]\n",
        "\n",
        "print(\"=== Summary ===\")\n",
        "print(summary)\n",
        "print(\"\\n\")\n",
        "\n",
        "question = \"What is the main idea of the article?\"\n",
        "result = qa(question=question, context=article)\n",
        "\n",
        "print(\"=== Question Answering ===\")\n",
        "print(\"Question:\", question)\n",
        "print(\"Answer:\", result[\"answer\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NswRQhF6zBQb",
        "outputId": "c238b12a-a8b6-4da0-e58c-a30c84e9f9e5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting summarization_qa.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python summarization_qa.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-hRX1Sk3jgc",
        "outputId": "1d8af510-381d-4c91-caaf-67e3e42ae2ef"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-09 21:00:05.522742: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765314005.585484   23414 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765314005.604945   23414 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765314005.661968   23414 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765314005.662027   23414 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765314005.662032   23414 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765314005.662036   23414 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-09 21:00:05.676188: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "=== Summary ===\n",
            "Google plans to launch smart glasses powered by artificial intelligence (AI) in 2026. Comes after its previous high-profile attempt to enter the market ended in failure. Will let users interact with its own AI products, such as its chatbot Gemini.\n",
            "\n",
            "\n",
            "=== Question Answering ===\n",
            "Question: What is the main idea of the article?\n",
            "Answer: Google plans to launch smart glasses powered by artificial intelligence (AI)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile fine_tuning.py\n",
        "\n",
        "from datasets import Dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    DataCollatorForLanguageModeling,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    pipeline\n",
        ")\n",
        "\n",
        "texts = [\n",
        "    \"Dania walked through the quiet streets of Amman, realizing the city held more stories than she ever imagined.\"\n",
        "    \"Every night, she returned to her small desk, where the glow of her laptop became the only light in the room.\"\n",
        "    \"The moment Dania opened her old notebook, memories of her first project came rushing back like a forgotten dream.\"\n",
        "    \"She had always believed that every dataset carried a secret, waiting for someone patient enough to uncover it.\"\n",
        "    \"One cold evening, a sudden idea struck her—an idea that felt strangely alive, like it had been waiting for her.\"\n",
        "    \"As the rain tapped softly on her window, Dania typed the first line of code that would change everything.\"\n",
        "    \"She paused, realizing that she wasn’t just building a model; she was building a version of herself she had never met.\"\n",
        "    \"Some nights, the silence felt heavy, but Dania learned to find comfort in the rhythm of her thoughts.\"\n",
        "    \"The old library at the University of Jordan became her second home, where stories of past students whispered through the shelves.\"\n",
        "    \"Just when she felt lost, a single line in her code finally worked, lighting up her face with quiet triumph.\"\n",
        "    \"With every experiment, Dania felt the world around her shrink, until only the story she was writing truly existed.\"\n",
        "    \"She once feared failure, but now she saw it as a character in her story—a character that pushed her forward.\"\n",
        "    \"In the stillness of the early morning, Dania realized that dreams grow louder when the world is quiet.\"\n",
        "    \"She knew that the journey would be long, but every chapter begins with a single brave sentence.\"\n",
        "    \"Dania closed her eyes for a moment, imagining the future she was slowly constructing with each key she pressed.\"\n",
        "\n",
        "]\n",
        "\n",
        "model_name = \"distilgpt2\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "model.config.pad_token_id = model.config.eos_token_id\n",
        "\n",
        "generator_before = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "print(\"=== BEFORE FINE-TUNING ===\")\n",
        "before_output = generator_before(\n",
        "    \"In the University of Jordan,\",\n",
        "    max_new_tokens=50,\n",
        "    do_sample=True,\n",
        "    top_k=50,\n",
        "    top_p=0.95\n",
        ")[0][\"generated_text\"]\n",
        "print(before_output)\n",
        "print(\"\\n\")\n",
        "\n",
        "tokenized = [\n",
        "    tokenizer(\n",
        "        t,\n",
        "        truncation=True,\n",
        "        padding=\"max_length\",\n",
        "        max_length=64\n",
        "    )\n",
        "    for t in texts\n",
        "]\n",
        "\n",
        "dataset = Dataset.from_dict({\n",
        "    \"input_ids\": [item[\"input_ids\"] for item in tokenized],\n",
        "    \"attention_mask\": [item[\"attention_mask\"] for item in tokenized],\n",
        "})\n",
        "\n",
        "data_collator = DataCollatorForLanguageModeling(\n",
        "    tokenizer=tokenizer,\n",
        "    mlm=False\n",
        ")\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./distilgpt2-finetuned\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=2,\n",
        "    logging_steps=5,\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset,\n",
        "    data_collator=data_collator\n",
        ")\n",
        "\n",
        "print(\"=== TRAINING... ===\")\n",
        "trainer.train()\n",
        "print(\"=== TRAINING DONE ===\\n\")\n",
        "\n",
        "generator_after = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "print(\"=== AFTER FINE-TUNING ===\")\n",
        "after_output = generator_after(\n",
        "    \"In the University of Jordan,\",\n",
        "    max_new_tokens=50,\n",
        "    do_sample=True,\n",
        "    top_k=50,\n",
        "    top_p=0.95\n",
        ")[0][\"generated_text\"]\n",
        "print(after_output)\n",
        "print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uynHdY5w7VqL",
        "outputId": "594aa98e-ae21-41d0-fb5a-552af167b106"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting fine_tuning.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python fine_tuning.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-B5ada6X9yMA",
        "outputId": "a210305d-82d4-40d5-e929-a3c02925d56f"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2025-12-09 22:42:29.678969: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1765320149.728624   47950 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1765320149.740478   47950 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1765320149.768934   47950 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765320149.768998   47950 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765320149.769007   47950 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1765320149.769015   47950 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-12-09 22:42:29.777284: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Device set to use cpu\n",
            "=== BEFORE FINE-TUNING ===\n",
            "In the University of Jordan, Jordan has been one of the country’s leading scientists and innovators and pioneers of sustainable energy. The university has made strides in innovation in the past 10 years, and continues to expand its mission to become the world’s leading greenhouse gas\n",
            "\n",
            "\n",
            "=== TRAINING... ===\n",
            "  0% 0/3 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n",
            "`loss_type=None` was set in the config but it is unrecognized. Using the default loss: `ForCausalLMLoss`.\n",
            "{'train_runtime': 29.14, 'train_samples_per_second': 0.103, 'train_steps_per_second': 0.103, 'train_loss': 3.632426897684733, 'epoch': 3.0}\n",
            "100% 3/3 [00:29<00:00,  9.71s/it]\n",
            "=== TRAINING DONE ===\n",
            "\n",
            "Device set to use cpu\n",
            "=== AFTER FINE-TUNING ===\n",
            "In the University of Jordan, Jordan‏s first female student, she was a full student, and she was a very good student. And she really wanted to be a member of the school.\n",
            "\n",
            "\n",
            "\n",
            "‏\n",
            "‏\n",
            "‏\n",
            "‏\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}